{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and loading data in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#____loading data____\n",
    "#df = pd.read_csv('../data/clean_house.csv')\n",
    "df = pd.read_csv('../data/clean_app.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['property_id', 'locality_name', 'postal_code', 'latitude', 'longitude',\n",
       "       'property_type', 'property_subtype', 'price', 'type_of_sale',\n",
       "       'number_of_rooms', 'living_area', 'kitchen_type',\n",
       "       'fully_equipped_kitchen', 'furnished', 'open_fire', 'terrace',\n",
       "       'terrace_area', 'garden', 'garden_area', 'surface_of_good',\n",
       "       'number_of_facades', 'swimming_pool', 'state_of_building', 'main_city',\n",
       "       'province'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA summary\n",
    "\n",
    "- we have a dataframe with 25 columns\n",
    "- 8 columns have categorical data:\n",
    "    - locality_name\n",
    "    - main_city\n",
    "    - province\n",
    "    - property_type\n",
    "    - type_of_sale\n",
    "    - kitchen_type\n",
    "    - state_of_building\n",
    "    - property_subtype\n",
    "\n",
    "- for houses we have 11394 rows\n",
    "\n",
    "- These are the columns that have null values:\n",
    "\n",
    "```\n",
    "    number_of_rooms           8188\n",
    "    terrace_area              7969\n",
    "    swimming_pool             7550\n",
    "    garden_area               7511\n",
    "    furnished                 7404\n",
    "    garden                    6775\n",
    "    terrace                   4813\n",
    "    kitchen_type              4046\n",
    "    fully_equipped_kitchen    2422\n",
    "    state_of_building         2338\n",
    "    number_of_facades         1765\n",
    "    latitude                  1468\n",
    "    longitude                 1468\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns\n",
    "\n",
    "- `property_id` uniquely identifies a property (therefor it is not very useful for predicting a given outcome)\n",
    "- same for `latitude`/`longitude` --> they were handy for the visuals, but have no added value for training a model\n",
    "- `property_type` is not useful for predicting a given outcome as well as the split of houses and appartments was already done upfront in the cleaning resulting in different files\n",
    "- `type_of_sale` is not useful for predicting a given outcome as most properties have a \"BUY REGULAR\" as value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____dropping unnecessary columns____\n",
    "# for house and app\n",
    "columns_to_drop = ['property_id', 'latitude', 'longitude', 'property_type', 'type_of_sale', 'fully_equipped_kitchen']\n",
    "\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for app only\n",
    "\n",
    "app_columns_to_drop = ['surface_of_good']\n",
    "\n",
    "df.drop(app_columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling up swimming pool column with 0 when value is not filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____imputing missing values for swimmingpool____\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "constant_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "df[['swimming_pool']] = constant_imputer.fit_transform(df[['swimming_pool']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding\n",
    "\n",
    "- To handle columns:\n",
    "\n",
    "- kitchen_type              4046 --> object      -----> One Hot Encoding\n",
    "- state_of_building         2338 --> object      -----> One Hot Encoding\n",
    "- property_subtype          0                    -----> One Hot Encoding    \n",
    "\n",
    "    ```\n",
    "    number_of_rooms           8188\n",
    "    terrace_area              7969\n",
    "    garden_area               7511\n",
    "    furnished                 7404 --> 1/0 or NaN\n",
    "    garden                    6775 --> 1/0 or NaN\n",
    "    terrace                   4813 --> 1/0 or NaN\n",
    "    fully_equipped_kitchen    2422 --> 1/0 or NaN\n",
    "    number_of_facades         1765\n",
    "    ```\n",
    "\n",
    "`OneHotEncoder` from the `sklearn.preprocessing` module and `pd.get_dummies` from pandas are both used for one-hot encoding categorical variables.\n",
    "\n",
    "The main differences are:\n",
    "\n",
    "- `OneHotEncoder` is typically used in a machine learning pipeline within scikit-learn, while `pd.get_dummies` is a pandas function.\n",
    "- `OneHotEncoder` requires you to first fit the encoder on the data and then transform it, while `pd.get_dummies` can be applied directly to the DataFrame.\n",
    "- `OneHotEncoder` returns a sparse matrix by default, which can be memory efficient for large datasets, while `pd.get_dummies` returns a pandas DataFrame.\n",
    "- `OneHotEncoder` can handle new categories not seen during fitting better than `pd.get_dummies`.\n",
    "- Depending on your workflow and requirements, you can choose between the two options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____one-hot encoding for kitchen_type____\n",
    "df = pd.get_dummies(df, columns=[\"kitchen_type\"], prefix=\"kitchen_type\")\n",
    "\n",
    "# _____one-hot encoding for state_of_building____\n",
    "df = pd.get_dummies(df, columns=[\"state_of_building\"], prefix=\"state_of_building\")\n",
    "\n",
    "# _____one-hot encoding for property_subtype____\n",
    "df = pd.get_dummies(df, columns=[\"property_subtype\"], prefix=\"property_subtype\")\n",
    "\n",
    "# _____one-hot encoding for province____\n",
    "df = pd.get_dummies(df, columns=[\"province\"], prefix=\"province\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a training and test set\n",
    "\n",
    "\n",
    "#### Stratified sampling\n",
    "\n",
    "- Can be used for when y is more classification values\n",
    "    `X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)`\n",
    "\n",
    "#### About datatypes\n",
    "\n",
    "- X and y can be dataframes or of the type series (it all depends on the model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____defining target and features____\n",
    "\n",
    "columns_to_drop = ['price', 'locality_name', 'main_city']\n",
    "\n",
    "# Drop the specified columns\n",
    "X = df.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____creating training and testing sets____\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "\n",
    "- replacing missing values with statistical estimates of these missing data of these missing data or with arbitrary values\n",
    "- it's common to use the mean or median to fill in missing values\n",
    "- for categorical values we can use the mode (most frequent value)\n",
    "- !!! must split our data first, to avoid data leakage !!!\n",
    "- flag as missing or -1 or -999\n",
    "\n",
    "https://medium.com/mastering-the-art-of-data-science-a-comprehensive/mastering-data-preprocessing-and-feature-engineering-for-machine-learning-missing-basic-data-a648d2cb1196#:~:text=Missing%20Data%20Imputation%3A%20Imputation%20is,models%20or%20obtain%20their%20predictions.\n",
    "\n",
    "- These are the columns that have missing values in our case (for houses):\n",
    "\n",
    "    ```\n",
    "    number_of_rooms           8188\n",
    "    terrace_area              7969\n",
    "    swimming_pool             7550 --> 1/0 or NaN\n",
    "    garden_area               7511\n",
    "    furnished                 7404 --> 1/0 or NaN\n",
    "    garden                    6775 --> 1/0 or NaN\n",
    "    terrace                   4813 --> 1/0 or NaN\n",
    "    kitchen_type              4046 --> object      -----> One Hot Encoding\n",
    "    fully_equipped_kitchen    2422 --> 1/0 or NaN  -----> REMOVED (wrong logic)\n",
    "    state_of_building         2338 --> object      -----> One Hot Encoding\n",
    "    number_of_facades         1765\n",
    "    property_subtype          0                    -----> One Hot Encoding\n",
    "    ```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Simple Imputation \n",
    "\n",
    "- filling with mean value: `missing = lambda x: x.fillna(x.mean())`\n",
    "- or filling with median value: `missing = lambda x: x.fillna(x.median())`\n",
    "- then using transform(): `df = df.transform(missing)`\n",
    "\n",
    "- or do the same in another way:\n",
    "    ``` python\n",
    "    mean_value = df['column_name'].mean()\n",
    "    df['column_name'] = df['column_name'].fillna(mean_value, inplace=True)\n",
    "    ```\n",
    "- SimpleImputer\n",
    "\n",
    "    ```python\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    df[['column_name']] = mean_imputer.fit_transform(df[['column_name']])\n",
    "    \n",
    "    constant_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-999)\n",
    "    df[['column_name']] = constant_imputer.fit_transform(df[['column_name']])\n",
    "\n",
    "    frequent_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    df[['column_name']] = frequent_imputer.fit_transform(df[['column_name']])\n",
    "\n",
    "    constant_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=MISS)\n",
    "    df[['column_name']] = constant_imputer.fit_transform(df[['column_name']])\n",
    "    ```\t\n",
    "\n",
    "### Advanced Imputation\n",
    "\n",
    "- ! important to first normalize the data !\n",
    "\n",
    "- K-nearest neighbors\n",
    "- SMOTE (synthetic minority over-sampling technique)\n",
    "\n",
    "    ``` Python\n",
    "    from sklearn.impute import KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "    df['column_name'] = imputer.fit_transform(df['column_name'])\n",
    "    ```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____imputing -1 for missing values for number_of_rooms, terrace_area, garden_area, furnished, garden, terrace, number_of_facades____\n",
    "\n",
    "constant_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "\n",
    "colums_to_impute = ['number_of_rooms', 'terrace_area', 'garden_area', 'furnished', 'garden', 'terrace', 'number_of_facades']\n",
    "\n",
    "X_train[colums_to_impute] = constant_imputer.fit_transform(X_train[colums_to_impute])\n",
    "X_test[colums_to_impute] = constant_imputer.fit_transform(X_test[colums_to_impute])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "- not removing the outliers gives a worse score for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linmodel training score:  0.43539090104062006\n",
      "linmodel testscore:  0.39334018497499834\n",
      "rmse:  273950.3012086112\n",
      "train_r2_score:  0.43539090104062006\n",
      "test_r2_score:  0.39334018497499834\n",
      "cross val score:  0.42704685976449064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics  \n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "linmodel = LinearRegression()\n",
    "\n",
    "#____train the model____\n",
    "linmodel.fit(X_train, y_train)\n",
    "\n",
    "#____show the score____\n",
    "print(\"linmodel training score: \", linmodel.score(X_train, y_train))\n",
    "\n",
    "#____test the model____\n",
    "y_lin_prediction = linmodel.predict(X_test)\n",
    "\n",
    "#____show the score____\n",
    "print(\"linmodel testscore: \", linmodel.score(X_test, y_test))\n",
    "\n",
    "#____show the rmse____\n",
    "mse = sklearn.metrics.mean_squared_error(y_test, y_lin_prediction)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"rmse: \",rmse)\n",
    "\n",
    "#____show the r2_score____\n",
    "print(\"train_r2_score: \", r2_score(y_train, linmodel.predict(X_train)))\n",
    "print(\"test_r2_score: \", r2_score(y_test, linmodel.predict(X_test)))\n",
    "\n",
    "\n",
    "print(\"cross val score: \", cross_val_score(linmodel, X_train, y_train).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.subplots(figsize = (7, 7))\n",
    "\n",
    "plt.scatter(y_test, y_lin_prediction)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'y', lw=2)\n",
    "plt.xlabel(\"Real prices\", size=10)\n",
    "plt.ylabel(\"Predicted prices\", size=10)\n",
    "plt.title(\"Linear Regression\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression\n",
    "\n",
    "!! runs 5m34s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomforest choosen max_depth:  20\n",
      "randomforest choosen n_estimators:  100\n",
      "randomforest training score:  0.965682942420527\n",
      "randomforest testscore:  0.6933619773660971\n",
      "rmse:  194765.56315312724\n",
      "cross val score:  0.7722122448192401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics  \n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10, 15, 20, 25, 30, 40],\n",
    "    'n_estimators': [100, 200]}\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid=param_grid)\n",
    "grid.fit(X, y)\n",
    "dept = grid.best_params_['max_depth']\n",
    "estimators = grid.best_params_['n_estimators']\n",
    "\n",
    "randomforest = RandomForestRegressor(n_estimators = estimators, max_depth = dept)\n",
    "\n",
    "#____train the model____\n",
    "randomforest.fit(X_train, y_train)\n",
    "\n",
    "#____show the choosen max_depth____\n",
    "print(\"randomforest choosen max_depth: \", dept)\n",
    "\n",
    "#____show the choosen n_estimators____\n",
    "print(\"randomforest choosen n_estimators: \", estimators)\n",
    "\n",
    "#____show the score____\n",
    "print(\"randomforest training score: \", randomforest.score(X_train, y_train))\n",
    "\n",
    "#____test the model____\n",
    "y_prediction = randomforest.predict(X_test)\n",
    "\n",
    "#____show the score____\n",
    "print(\"randomforest testscore: \", randomforest.score(X_test, y_test))\n",
    "\n",
    "mse = sklearn.metrics.mean_squared_error(y_test, y_prediction)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"rmse: \",rmse)\n",
    "\n",
    "print(\"cross val score: \", cross_val_score(randomforest, X_train, y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.subplots(figsize = (7, 7))\n",
    "\n",
    "plt.scatter(y_test, y_prediction)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'y', lw=2)\n",
    "plt.xlabel(\"Real prices\", size=10)\n",
    "plt.ylabel(\"Predicted prices\", size=10)\n",
    "plt.title(\"Random Forest\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#feature importance\n",
    "importance_rf = pd.Series(randomforest.feature_importances_, index=X.columns)\n",
    "\n",
    "#sort importances\n",
    "sorted_importance_rf = importance_rf.sort_values()\n",
    "\n",
    "sorted_importance_rf.plot(kind='barh', color='lightgreen', figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([231403.57125])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_app_data = {\n",
    "    'postal_code' :[2050],\n",
    "    'number_of_rooms' :[-1],\n",
    "    'living_area' :[100.0],\n",
    "    'furnished':[0],\n",
    "    'open_fire':[0],\n",
    "    'terrace':[1.0],\n",
    "    'terrace_area':[5.0],\n",
    "    'garden':[0],\n",
    "    'garden_area':[0.0],\n",
    "    'number_of_facades':[2],\n",
    "    'swimming_pool': [0.0],\n",
    "    'kitchen_type_HYPER_EQUIPPED': [0.0],\n",
    "    'kitchen_type_INSTALLED': [1.0],\n",
    "    'kitchen_type_NOT_INSTALLED': [0.0],\n",
    "    'kitchen_type_SEMI_EQUIPPED': [0.0],\n",
    "    'kitchen_type_USA_HYPER_EQUIPPED': [0.0],\n",
    "    'kitchen_type_USA_INSTALLED': [0.0],\n",
    "    'kitchen_type_USA_SEMI_EQUIPPED': [0.0],\n",
    "    'kitchen_type_USA_UNINSTALLED': [0.0],\n",
    "    'state_of_building_AS_NEW': [0.0],\n",
    "    'state_of_building_GOOD': [0.0],\n",
    "    'state_of_building_JUST_RENOVATED': [0.0],\n",
    "    'state_of_building_TO_BE_DONE_UP': [0.0],\n",
    "    'state_of_building_TO_RENOVATE': [0.0],\n",
    "    'state_of_building_TO_RESTORE': [0.0],\n",
    "    'property_subtype_APARTMENT': [1.0], \n",
    "    'property_subtype_DUPLEX': [0.0],\n",
    "    'property_subtype_FLAT_STUDIO': [0.0],\n",
    "    'property_subtype_GROUND_FLOOR': [0.0],\n",
    "    'property_subtype_KOT': [0.0],\n",
    "    'property_subtype_LOFT': [0.0],\n",
    "    'property_subtype_PENTHOUSE': [0.0],\n",
    "    'property_subtype_SERVICE_FLAT': [0.0],\n",
    "    'property_subtype_TRIPLEX': [0.0],\n",
    "    'province_antwerpen': [1.0],\n",
    "    'province_brussel': [0.0],\n",
    "    'province_henegouwen': [0.0],\n",
    "    'province_limburg': [0.0],\n",
    "    'province_luik': [0.0],\n",
    "    'province_luxemburg': [0.0],\n",
    "    'province_namen': [0.0],\n",
    "    'province_oost-vlaanderen': [0.0],\n",
    "    'province_vlaams-brabant': [0.0],\n",
    "    'province_waals-brabant': [0.0],\n",
    "    'province_west-vlaanderen': [0.0]\n",
    "    }\n",
    "\n",
    "test_df = pd.DataFrame(one_app_data)\n",
    "\n",
    "y_prediction = randomforest.predict(test_df)\n",
    "y_prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
