{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING A PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#____loading data____\n",
    "df = pd.read_csv('./data/clean_house.csv')\n",
    "# df = pd.read_csv('./data/clean_app.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____defining target and features____\n",
    "target_column_to_drop = ['price']\n",
    "X = df.drop(columns=target_column_to_drop, axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____Define the columns you want to drop______\n",
    "columns_to_drop = ['property_id', 'latitude', 'longitude', 'property_type', 'type_of_sale', 'fully_equipped_kitchen', 'locality_name', 'main_city']\n",
    "X = X.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for app only\n",
    "\n",
    "app_columns_to_drop = ['surface_of_good']\n",
    "\n",
    "# X_train = X_train.drop(columns=app_columns_to_drop, axis=1)\n",
    "# y_train = y_train.drop(columns=app_columns_to_drop, axis=1)\n",
    "\n",
    "X = X.drop(columns=app_columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____imputing missing values for swimmingpool____\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Define the imputer to replace missing values with 0.0\n",
    "constant_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0.0)\n",
    "\n",
    "# Define the column containing missing values\n",
    "columns_with_missing_values = ['swimming_pool']\n",
    "\n",
    "# Impute missing values in X_train\n",
    "X[columns_with_missing_values] = constant_imputer.fit_transform(X[columns_with_missing_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____one-hot encoding for kitchen_type____\n",
    "X = pd.get_dummies(X, columns=[\"kitchen_type\"], prefix=\"kitchen_type\")\n",
    "\n",
    "# _____one-hot encoding for state_of_building____\n",
    "X = pd.get_dummies(X, columns=[\"state_of_building\"], prefix=\"state_of_building\")\n",
    "\n",
    "# _____one-hot encoding for property_subtype____\n",
    "X = pd.get_dummies(X, columns=[\"property_subtype\"], prefix=\"property_subtype\")\n",
    "\n",
    "# _____one-hot encoding for province____\n",
    "X = pd.get_dummies(X, columns=[\"province\"], prefix=\"province\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____creating training and testing sets____\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _____imputing -1 for missing values for number_of_rooms, terrace_area, garden_area, furnished, garden, terrace, number_of_facades____\n",
    "\n",
    "constant_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "\n",
    "colums_to_impute = ['number_of_rooms', 'terrace_area', 'garden_area', 'furnished', 'garden', 'terrace', 'number_of_facades']\n",
    "\n",
    "\n",
    "X_train[colums_to_impute] = constant_imputer.fit_transform(X_train[colums_to_impute])\n",
    "X_test[colums_to_impute] = constant_imputer.fit_transform(X_test[colums_to_impute])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and predicting the model\n",
    "\n",
    "```python\t\n",
    "# latest results for houses\n",
    "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
    "randomforest choosen max_depth:  20\n",
    "randomforest choosen n_estimators:  100\n",
    "randomforest training score:  0.9591154789033177\n",
    "randomforest testscore:  0.7096580474996514\n",
    "rmse:  156079.94095185387\n",
    "cross val score:  0.7267999915259765\n",
    "\n",
    "# latest results for apartments\n",
    "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
    "randomforest choosen max_depth:  20\n",
    "randomforest choosen n_estimators:  200\n",
    "randomforest training score:  0.9657029558400106\n",
    "randomforest testscore:  0.7043570191397667\n",
    "rmse:  191241.85796628642\n",
    "cross val score:  0.77146716370121\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "randomforest choosen max_depth:  20\n",
      "randomforest choosen n_estimators:  100\n",
      "randomforest training score:  0.9591154789033177\n",
      "randomforest testscore:  0.7096580474996514\n",
      "rmse:  156079.94095185387\n",
      "cross val score:  0.7267999915259765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import sklearn.metrics  \n",
    "import math\n",
    "\n",
    "# cv =3 for 3fold cross validation\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10, 15, 20, 25, 30, 40],\n",
    "    'n_estimators': [100, 200]}\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid=param_grid, cv=3, verbose=1)\n",
    "grid.fit(X, y)\n",
    "dept = grid.best_params_['max_depth']\n",
    "estimators = grid.best_params_['n_estimators']\n",
    "\n",
    "randomforest = RandomForestRegressor(n_estimators = estimators, max_depth = dept)\n",
    "\n",
    "#____train the model____\n",
    "randomforest.fit(X_train, y_train)\n",
    "\n",
    "#____show the choosen max_depth____\n",
    "print(\"randomforest choosen max_depth: \", dept)\n",
    "\n",
    "#____show the choosen n_estimators____\n",
    "print(\"randomforest choosen n_estimators: \", estimators)\n",
    "\n",
    "#____show the score____\n",
    "print(\"randomforest training score: \", randomforest.score(X_train, y_train))\n",
    "\n",
    "#____test the model____\n",
    "y_prediction = randomforest.predict(X_test)\n",
    "\n",
    "#____show the score____\n",
    "print(\"randomforest testscore: \", randomforest.score(X_test, y_test))\n",
    "\n",
    "mse = MSE(y_test, y_prediction)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"rmse: \",rmse)\n",
    "\n",
    "print(\"cross val score: \", cross_val_score(randomforest, X_train, y_train).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "params = dict(\n",
    "    regressor__max_depth = [10, 15, 20, 25, 30],\n",
    "    regressor__n_estimators = [100, 200]\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=params)\n",
    "gs = grid_search.fit(X_train, y_train).best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
